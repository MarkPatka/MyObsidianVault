Топики разделены на партиции, то есть топик разбит на несколько «корзин» (buckets), расположенных на разных брокерах Kafka. Такое распределенное размещение ваших данных очень важно для масштабируемости, поскольку оно позволяет клиентским приложениям одновременно читать и записывать данные из/во множество брокеров. 

Когда новое событие публикуется в топик, оно фактически добавляется в одну из партиций топика. ==События с одинаковым ключом события (например, ID клиента или транспортного средства) записываются в одну и ту же партицию, и Kafka гарантирует, что любой потребитель данной партиции топика будет всегда читать события этой партиции точно в том же порядке, в каком они были записаны==.

![[kafka-image-partitions.png]]

### Cтратегии партиционирования

| Стратегия                                             | Описание                                                                                       | Преимущества                                                                                       |
| :---------------------------------------------------- | :--------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------- |
| **Стандартный партиционер (Default)**                 | Использует **хеш ключа**. Сообщения с `null`-ключом отправляются по round-robin.               | Гарантирует **порядок для одинаковых ключей**. Равномерное распределение при разнообразных ключах. |
| **Round-robin партиционер**                           | Сообщения отправляются в партиции **по очереди**, независимо от ключа.                         | **Максимально равномерное** распределение нагрузки.                                                |
| **Равномерный "липкий" партиционер (Uniform Sticky)** | "Прилипает" к одной партиции на время заполнения батча. Ключ игнорируется для выбора партиции. | **Максимальная производительность** за счет крупных батчей. Снижает задержку.                      |
| **Пользовательский партиционер (Custom)**             | Реализация интерфейса `Partitioner` с собственной логикой.                                     | **Полная гибкость** (логика на основе данных, внешнего состояния и т.д.).                          |

### Выбор стратегии партиционирования

```mermaid
flowchart TD
    B{Важен ли порядок<br>сообщений?}

    B -- "Да, для определенного ключа" --> C[Использовать ключ сообщения]
    C --> D[Стандартный партиционер<br>Гарантирует порядок для ключа]

    B -- "Нет, важна макс. пропускная способность" --> E[Использовать null-ключ<br>или явно указать]
    E --> F[Равномерный 'липкий' партиционер<br>Макс. производительность]

    B -- "Нет, нужна особая логика<br>(e.g., по региону)" --> G[Пользовательский партиционер]
    G --> H[Полная гибкость<br>Высокая сложность]
``````


### Как устроены партиции в топиках

Формально партиция и есть строго упорядоченный лог сообщений. Каждое сообщение в ней добавлено в конец без возможности изменить его в будущем и как-то повлиять на уже записанные сообщения. При этом сам топик в целом не имеет никакого порядка, но порядок сообщений всегда есть в одной из его партиций.

Разберём детали на примере. В кластере Kafka есть три брокера: 101, 102 и 103. Топик A отмечен бирюзовым, топик B — жёлтым, C — оранжевым. На картинке у каждого топика по три партиции, но их число может быть разным и настраивается для каждого топика.

![[kafka-image-segments.png]]

Партиции распределены между брокерами — кластер Kafka делает это автоматически при создании топика. Инструмент автоматически не следит за размером каждой партиции, не занимается ребалансировкой записи и чтения в кластере, не перемещает партиции между брокерами. Для этого уже существуют opensource-инструменты и готовые enterprise-платформы как [[Confluent Intro|Confluent]], но сейчас для нас это не важно.

Каждая партиция на брокере представлена набором сегментов. Число сегментов у партиций тоже может быть разным. Оно варьируется в зависимости от интенсивности записи и настроек размера сегмента.

В итоге, мы можем увеличивать число брокеров в кластере и тем самым масштабировать систему. Kafka поддерживает добавление или удаление брокеров. А с помощью встроенных инструментов можно, например, переносить партиции между брокерами чтобы равномерно их распределять.

Можно также добавлять новые партиции в топике — это увеличит параллелизм записи и чтения со стороны продюсера и консумера.