### Event Streaming (Потоковая обработка событий)

 Это практика
1. Захвата данных в реальном времени из таких источников событий, как базы данных, датчики, мобильные устройства, облачные сервисы и программные приложения, в виде потоков событий; 
2. Надежного хранения этих потоков событий для последующего извлечения, манипулирования, обработки и реакции на потоки событий как в реальном времени, так и ретроспективно; 
3. Маршрутизации потоков событий к различным технологиям-получателям по мере необходимости. 

Таким образом, потоковая обработка событий обеспечивает непрерывный поток и интерпретацию данных, чтобы нужная информация находилась в нужном месте в нужное время.

**Для чего можно использовать потоковую обработку событий?**

Потоковая обработка событий применяется в самых разных сценариях использования в многочисленных отраслях и организациях. Вот несколько примеров:

- Для обработки платежей и финансовых транзакций в реальном времени, например, на фондовых биржах, в банках и страховых компаниях.
- Для отслеживания и мониторинга автомобилей, грузовиков, автопарков и грузов в реальном времени, например, в логистике и автомобильной промышленности.
- Для непрерывного сбора и анализа данных с датчиков устройств Интернета вещей (IoT) или другого оборудования.
- Для сбора и немедленной реакции на взаимодействия и заказы клиентов, например, в розничной торговле, гостиничном и туристическом бизнесе, а также в мобильных приложениях.
- Для мониторинга пациентов в больницах и прогнозирования изменений в их состоянии для обеспечения своевременного лечения в чрезвычайных ситуациях.
- Для соединения, хранения и предоставления доступа к данным, производимым различными подразделениями компании.
- Для использования в качестве основы для платформ данных, событийно-ориентированных архитектур (event-driven architectures) и микросервисов.

**Apache Kafka** — это платформа для потоковой обработки событий.

Kafka объединяет три ключевые возможности, что позволяет реализовать ваши сценарии использования потоковой обработки событий от начала и до конца с помощью единой проверенной в боях платформы:

1. Публиковать (записывать) и подписываться (читать) на потоки событий, включая непрерывный импорт/экспорт ваших данных из других систем и в них.
2. Надежно и долговременно хранить потоки событий столько, сколько вам нужно.
3. Обрабатывать потоки событий по мере их поступления или ретроспективно.

И вся эта функциональность предоставляется распределенным, _highly scalable (легко масштабируемым)_, эластичным, отказоустойчивым и безопасным образом. Kafka можно развернуть на bare-metal-оборудовании, виртуальных машинах и в контейнерах, как локально (on-premises), так и в облаке. Вы можете выбрать между самостоятельным управлением средами Kafka и использованием полностью управляемых сервисов, предлагаемых различными поставщиками.

---
### Гарантия доставки

Со стороны продюсера разработчик определяет надёжность доставки сообщения до Kafka с помощью параметра **_acks_**. Указывая **_0_** или **_none_**, продюсер будет отправлять сообщения в Kafka, не дожидаясь никаких подтверждений записи на диск со стороны брокера.

Это самая слабая гарантия. В случае выхода брокера из строя или сетевых проблем, вы так и не узнаете, попало сообщение в лог или просто потерялось.

![[kafka-image-ack.png]]

Указывая настройку в **_1_** или **_leader_**, продюсер при записи будет дожидаться ответа от брокера с лидерской партицией — значит, сообщение сохранено на диск одного брокера. В этом случае вы получаете гарантию, что сообщение было получено по крайней мере один раз, но это всё ещё не страхует вас от проблем в самом кластере.

Представьте, что в момент подтверждения брокер с лидерской партиции выходит из строя, а фолловеры не успели отреплицировать с него данные. В таком случае вы теряете сообщение и снова не узнаёте об этом. Такие ситуации случаются редко, но они возможны.

Наконец, устанавливая acks в **_-1_** или **_all_**, вы просите брокера с лидерской партицией отправить вам подтверждение только тогда, когда запись попадёт на локальный диск брокера и в реплики-фолловеры. Число этих реплик устанавливает настройка `**_min.insync.replicas_**`.

Частая ошибка при конфигурировании топика — выбор `_min.insync.replicas_` по числу реплик. При таком сценарии в случае выхода из строя брокера и потери одной реплики продюсер больше не сможет записывать сообщение в кластер, поскольку не дождётся подтверждения. Лучше предусмотрительно устанавливать `_min.insync.replicas_` на единицу меньше числа реплик. 

Очевидно, что третья схема достаточно надёжна, но она требует больше накладных расходов: мало того, чтобы нужно сохранить на диск, так ещё и дождаться, пока фолловеры отреплицируют сообщения и сохранят их к себе на диск в лог.

---
### Семантики доставки

В любых очередях есть выбор между скоростью доставки и расходами на надёжность. Цветные квадратики на слайде — это сообщения, которые мы будем записывать в очередь, выбирая нужную из семантик.

![[kafka-image-semantics.png]]

- Семантика **_at-most once_** означает, что при доставке сообщений нас устраивают потери сообщений, но не их дубликаты. Это самая слабая гарантия, которую реализуют брокерами очередей
- Семантика **_at-least once_** означает, что мы не хотим терять сообщения, но нас устраивают возможные дубликаты
- Семантика **_exactly-once_** означает, что мы хотим доставить одно и только одно сообщение, ничего не теряя и ничего не дублируя.

На первый взгляд самой правильной для любого приложения кажется семантика exactly once, однако это не всегда так. Например, при передаче партнёрских координат вовсе не обязательно сохранять каждую точку из них, и вполне хватит at-most once. А при обработке идемпотентных событий нас вполне может и устроить дубль, если статусная модель предполагает его корректную обработку.

В распределённых системах у exactly-once есть своя цена: высокая надёжность означает большие задержки.

---
### Репликация (Replication):

Чтобы сделать ваши данные отказоустойчивыми и высокодоступными, каждый топик может быть реплицирован, даже между географическими регионами или центрами обработки данных. Это означает, что всегда есть несколько брокеров, у которых есть копия данных на случай сбоев, необходимости обслуживания брокеров и т.д. Распространенная production-настройка — коэффициент репликации 3, то есть у ваших данных всегда будет три копии. Эта репликация выполняется на уровне партиций топика.

![[kafka-image-replication.png]]

У каждой партиции есть настраиваемое число реплик, на изображении их три. Одна из этих реплик называется **_лидером_**, остальные — **_фолловерами_**. Продюсер подключается к брокеру, на котором расположена лидер-партиция, чтобы записать в неё данные.

![[kafka-image-replication-2.png]]

Записанные в лидера данные автоматически реплицируются фолловерами внутри кластера Kafka. Они подключаются к лидеру, читают данные и асинхронно сохраняют к себе на диск. В настроенном кластере Kafka репликация обычно занимает доли секунд.

Консумеры со своей стороны также читают из лидерской партиции — это позволяет достичь консистентности при работе с данными. Задача фолловеров здесь как и в предыдущем случае сводится к копированию данных от лидера.

==С версии 2.4 Kafka поддерживает чтение консумерами из фолловеров, основываясь на их взаимном расположении. Это полезно для сокращения задержек при обращении к ближайшему брокеру в одной зоне доступности. Однако, из-за асинхронной работы репликации, взамен вы получаете от фолловеров менее актуальные данные, чем они есть в лидерской партиции.==

Роли лидеров и фолловеров не статичны. Kafka автоматически выбирает роли для партиций в кластере. Например, в случае сбоя брокера, роль лидера достанется одной из реплик, а консумеры и продюсеры должны получить обновления согласно протоколу и переподключиться к брокерам с новыми лидерами партиций.

![[kafka-image-replication-3.png]]

В случае если Broker с Leader-репликой оказывается недоступен, роль лидера определяется протоколом **KRaft** на основании механизма ==**in-sync replicas (ISR)**:  в момент записи в Leader-реплику производится синхронная запись в Follower-реплику(-и), помеченную как ISR.== ISR-follower это надежный кандидат на нового Leader при необходимости его переключения.

---

### Идемпотентные продюсеры

![[kafka-image-idempotent-producers.png]]

Даже с выбором **_acks=all_** возможны дубликаты сообщений. В штатном режиме работы продюсер отправляет сообщение брокеру, а тот сохраняет данные в логе на диске и отправляет подтверждение продюсеру. Последний снова формирует пачку сообщений и так далее. Но ни одна программа не застрахована от сбоев.

Что, если брокер не смог отправить подтверждение продюсеру из-за сетевых проблем? В таком случае, продюсер повторно отправляет сообщение брокеру. Брокер послушно сохраняет добавляет ещё одно сообщение в лог — появляется дубликат.

Эта проблема решается в Kafka благодаря транзакционному API и использованию идемпотентности. В брокере есть специальная опция, которая включает идемпотентность — `_enable.idempotence_`. Так каждому сообщению будет проставлен идентификатор продюсера или PID и монотонно увеличивающийся sequence number. За счёт этого сообщения-дубликаты от одного продюсера с одинаковым PID будут отброшены на стороне брокера.

Если говорить проще — когда вы используете _acks=all_, нет никаких причин не включать `_enable.idempotence_` для своих продюсеров. Так вы добьётесь гарантии exactly once при записи в брокер и избежите дубликатов. Но у этого могущества есть своя цена — запись будет идти дольше.

---
### Консумер-группы

Странно, если бы чтением всех партиций занимался только один консумер. Они могут быть объединены в кластер — **_консумер-группы_**.

![[kafka-image-consumer-group.png]]

Перед глазами у вас каноничная диаграмма: с левой стороны продюсеры, в середине топики, а справа расположены консумеры. Есть два продюсера, каждый из которых пишет в свой топик, у каждого топика есть три партиции. 

Есть одна консумер-группа с двумя экземплярами одной и той же программы — это одна и та же программа, запущенная два раза. Эта программа-консумер читает два топика: X и Y.

Консумер подключается к брокеру с лидерской партицией, пуллит изменения в партиции, считывает сообщения, наполняет буфер, а затем проводит обработку полученных сообщений.

Обратите внимание, что партиции распределены кооперативно: каждому потребителю досталось по три партиции. Распределение партиций между консумерами в пределах одной группы выполняется автоматически на стороне брокеров. Kafka старается честно распределять партиции между консумер-группами, насколько это возможно.

Каждая такая группа имеет свой идентификатор, что позволяет регистрироваться на брокерах Kafka. Пространство имён консумер-групп глобально, а значит их имена в кластере Kafka уникальны.

Наконец, самое главное: Kafka сохраняет на своей стороне текущий оффсет по каждой партиции топиков, которые входят в состав консумер-группы. При подключении или отключении консумеров от группы, чтение продолжится с последней сохранённой позиции. Это делает консумер-группы незаменимыми при работе event-driven систем: мы можем без проблем деплоить наши приложения и не задумываться о хранении оффсета на стороне клиента.

Для этого консумер в группе, после обработки прочитанных сообщений отправляет запрос на сохранение оффсета — или коммитит свой оффсет. Технически, нет никаких ограничений на то, чтобы коммитить оффсет и до обработки сообщений, но для большинства сценариев разумнее делать это после.

---
### Ребалансировка консумер-групп

Рассмотрим сценарий, когда композиция группы меняется. В кластере Kafka консумер-группы создаются автоматически при подключении консумеров к кластеру и создавать её вручную нет необходимости, но это возможно через инструментарий. У новой группы отсутствуют сохранённые оффсеты партиций топиков и по умолчанию они равны -1.

![[kafka-image-rebalance-consumer-group.gif]]

При появлении новых участников в группе **_JoinGroup_**, в специальном процессе брокера Group Coordinator первому вошедшему консумеру присваивается роль Group Leader.

Лидер группы отвечает за распределение партиций между всеми участниками группы. Процесс поиска лидера группы, назначения партиций, стабилизации и подключения консумеров в группе к брокерам называется **ребалансировкой консумер-группы**.

Процесс ребалансировки группы по умолчанию заставляет все консумеры в группе прекратить чтение и дождаться полной синхронизации участников, чтобы обрести новые партиции для чтения. В Kafka есть и другие стратегии ребалансировки группы, включая **_Static membership_** или **_Cooperative Incremental Partition Assignor,_** но это тема для отдельной статьи.

Как только группа стала стабильной, а её участники получили партиции, консумеры в ней начинают чтение. Поскольку группа новая и раньше не существовала, то консумер выбирает позицию чтения оффсета: с самого начала earliest или же с конца latest. Топик мог существовать несколько месяцев, а консумер появился совсем недавно. В таком случае важно решить: читать ли все сообщения или же достаточно читать с конца самые последние, пропустив историю. Выбор между двумя опциями зависит от бизнес-логики протекающих внутри топика событий.

![[kafka-image-rebalance-consumer-group-2.gif]]

Если в группу добавить нового участника, процесс ребалансировки запускается повторно. Новому участнику вместе с остальными консумерами в группе будут назначены партиции, а лидер группы постарается их распределить между всеми более или менее честно, согласно выбранной им настраиваемой стратегии. Затем группа вновь переходит в стабильное состояние.

Чтобы Group Coordinator в кластере Kafka знал, какие из его участников активны и работают, а какие уже нет, каждый консумер в группе регулярно в равные промежутки времени отправляет **_Heartbeat-сообщение_**. Временное значение настраивается программой-консумером перед запуском.

Также консумер объявляет **_время жизни сессии_** — если за это время он не смог отправить ни одно из Heartbeat-сообщений брокеру, то покидает группу. Брокер, в свою очередь, не получив ни одно из Heartbeat-сообщений консумеров, запускает процесс ребалансировки консумеров в группе.

Процесс ребалансировки проходит достаточно болезненно для больших консумер-групп с множеством топиков. Он вызывает **_Stop-The-World_** во всей группе при малейшей смене композиции участников или состава партиций в топиках. Например, при смене лидера партиции в случае выхода брокера из кластера при причине аварии или плановых работах, Group Coordinator также инициирует ребалансировку.

Поэтому разработчикам программ-консумеров обычно рекомендуют использовать по одной консумер-группе на топик. Также полезно держать число потребителей не слишком большим, чтобы не запускать ребалансировку много раз, но и не слишком маленьким, чтобы сохранять производительность и надёжность при чтении.

Значения интервала Heartbeat и время жизни сессии следует устанавливать так, чтобы Heartbeat-интервал был в три-четыре раза меньше session timeout. Сами значения выбирайте не слишком большими, чтобы не увеличивать время до обнаружения «выпавшего» консумера из группы, но и не слишком маленьким, чтобы в случае малейших сетевых проблем, группа не уходила в ребалансировку.

![[kafka-image-consumers-2.png]]

Ещё один гипотетический сценарий: партиций в топике 4, а консумеров в группе 5. В этом случае группа будет стабилизирована, однако участники, которым не достанется ни одна из партиций, будут бездействовать. Такое происходит потому, что с одной партицией в группе может работать только один консумер, а два и более консумеров не могут читать из одной партиции в группе.

Отсюда возникает следующая базовая рекомендация: устанавливайте достаточное число партиций на старте, чтобы вы могли горизонтально масштабировать ваше приложение. Увеличение партиций в моменте не принесёт вам почти никакого результата. Уже записанные в лог сообщения нельзя переместить и распределить между новыми партициями средствами Kafka, а репартицирование своими силами всегда несёт риски, связанные с очерёдностью и идемпотентностью.

---
### Устаревание данных

В контексте сегментов стоит вспомнить и об их ротации. Когда сегмент достигает своего предела, он закрывается и вместо него открывается новый. Сегмент, в который сейчас записываются данные, называют **_активным сегментом_** — по сути это файл, открытый процессом брокеры. **_Закрытыми_** же называются те сегменты, в которых больше нет записи.

![[kafka-image-segments-3.png]]

Максимальную длину сегмента в байтах можно настроить глобально или индивидуально на каждый топик. Его размер определяет как часто старые файлы будут сменять новые. Если вы пишете много больших сообщений, следует увеличивать размер сегмента и, наоборот, не следует использовать большие сегменты, если вы редко пишете маленькие сообщения.

Простыми словами, настроенная политика устаревания не означает, к примеру, что из топика пропадут события старше 7 дней. Kafka удаляет закрытые сегменты партиций, а число таких партиций зависит от размера сегмента и интенсивности записи в партиции.

Но ничто не мешает хранить сообщения дольше или совсем их не удалять. Для хранения исторических данных в инструменте нет никаких ограничений, кроме размера дисков и числа брокеров, чтобы эти данные хранить.